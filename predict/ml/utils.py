import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from matplotlib.colors import ListedColormap
from predict.ml.settings_ml import ML_FEATURES, ML_TARGET
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from web.settings import BASE_DIR
import os
import statsmodels.formula.api as sm


NORMALIZER = lambda x: -1 if x<0 else 1


def invalid(f):
    '''
    Check whether the price is valid or not
    :param f: float
    :return: True if invalid else False
    '''
    if np.isnan(f) or np.isinf(f) or not np.isfinite(f):
        return True
    return False

def set_train_test(df):
    for index, row in df.iterrows():
        if invalid(row['hc']) or invalid(row['lc']) or invalid(row['oc']) or invalid(row['close_change']) or invalid(row['signal']):
            print(f'ERR-set_train_test: invalid value: {index}, {row}')
            # df.drop(index, axis=0, inplace=True)

    X = df.loc[:, ML_FEATURES].values
    y = df.loc[:, ML_TARGET].values

    # from sklearn.decomposition import PCA
    # pca = PCA()
    # pca.fit(X)
    # print(f'addd-set_train_test: {df.head()}')
    # print(f'addd-set_train_test: PCA.explained_variance_ratio={pca.explained_variance_ratio_}')
    # print(f'addd-set_train_test: PCA.explained_variance={pca.explained_variance_}')

    # Splitting the dataset into the Training set and Test set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

    """
    # Feature Scaling
    from sklearn.preprocessing import StandardScaler
    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.transform(X_test)
    sc_y = StandardScaler()
    y_train = sc_y.fit_transform(y_train)
    """

    """
    # ML_FEATURES = ['close', 'hc', 'lc', 'oc', 'close_change', 'volume_change']
    X = np.append(arr=np.ones((len(df), 1)).astype(int), values=X, axis=1)
    print(X.shape)
    # X_opt = X[:, range(len(ML_FEATURES))]
    X_opt = X[:, [0,1,2,3,4,5,6]]
    regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()
    sum = regressor_OLS.summary()
    print(sum)
    X_opt = X[:, [0,2,3,4,5,6]] #remove 'close'    
    regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()
    sum = regressor_OLS.summary()
    print(sum)
    X_opt = X[:, [0,2,3,4,5]] #remove 'volume_change'
    regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()
    sum = regressor_OLS.summary()
    print(sum)
    X_opt = X[:, [0,2,4,5]] #remove 'lc'
    regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()
    sum = regressor_OLS.summary()
    print(sum)
    X_opt = X[:, [0,2,5]] #remove 'oc'
    regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()
    sum = regressor_OLS.summary()
    print(sum)
    X_opt = X[:, [0,5]] #remove 'hc'
    regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()
    sum = regressor_OLS.summary()
    print(sum) # 'close_change' is the most important variable
    """

    # print(f'addd-ML preprocess dataset={len(df)}, X_train={len(X_train)}, X_test={len(X_test)}, y_train={len(y_train)}, y_test={len(y_test)}')
    return X_train, X_test, y_train, y_test

def stand_scale(X_train, X_test):
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    return X_train, X_test

def postprocess(y_pred, df, column_name, y_test):
    '''
    Normalize predicated values to -1, 0, 1, and append normalized values to signal columns
    :param y_pred: The values predicted by machine learning models
    :param df: The dataframe of historical data
    :param column_name: column mane of siganl generated by machine learning model, e.g., LINEAR_REGRESSION_signal
    :return: normalized predicted values
    '''
    y_pred_norm = list(map(NORMALIZER, y_pred))
    df[column_name] = df['signal']
    df.update(pd.Series(y_pred_norm, name=column_name, index=range(len(df)-len(y_pred), len(df))))

    # print(f'addd-postprocess: {column_name} Accuracy={accuracy_score(y_test, y_pred_norm, normalize=True)}')
    # print('addd-postprocess: {0} Predicated={1}'.format(column_name, 'SELL' if y_pred[-1]<0 else 'BUY'))
    return y_pred_norm

def plot(X_train, X_test, y_train, y_test, y_pred, df):
    # print(f'addd-slr: X_test: {X_train}')
    # print(f'addd-slr: y_pred: {y_train}')
    # print(f'addd-slr: X_test: {X_test}')
    # print(f'addd-slr: y_pred: {y_pred}')

    len_test = len(X_test)
    # # Visualising the Training set results
    # plt.scatter(X_train[:, 1], y_train, color='red')
    # plt.plot(X_test[:, 1], y_pred, color='blue')
    # plt.title('Salary vs Experience (Training set)')
    # plt.xlabel('Years of Experience')
    # plt.ylabel('Salary')
    # plt.show()

    # Visualising the Test set results
    plt.scatter(df.index[-len_test:], y_test, color='red')
    plt.scatter(df.index[-len_test:], y_pred, color='blue')
    plt.title('Gold (Test set)')
    plt.xlabel('Date')
    plt.ylabel('Signal')
    plt.show()


def visualize(X_train, X_test, y_train, y_test, classifier):
    # Visualising the Training set results
    X1, X2 = np.meshgrid(np.arange(start=X_train[:, 0].min() - 1, stop=X_train[:, 0].max() + 1, step=0.01),
                         np.arange(start=X_train[:, 1].min() - 1, stop=X_train[:, 1].max() + 1, step=0.01))
    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
                 alpha=0.75, cmap=ListedColormap(('red', 'green')))
    plt.xlim(X1.min(), X1.max())
    plt.ylim(X2.min(), X2.max())
    for i, j in enumerate(np.unique(y_train)):
        plt.scatter(X_test[y_train == j, 0], X_train[y_train == j, 1],
                    c=ListedColormap(('red', 'green'))(i), label=j)
    plt.title('Classifier (Training set)')
    plt.xlabel('Close')
    plt.ylabel('Signal')
    plt.legend()
    plt.show()

    # Visualising the Test set results
    X1, X2 = np.meshgrid(np.arange(start=X_test[:, 0].min() - 1, stop=X_test[:, 0].max() + 1, step=0.01),
                         np.arange(start=X_test[:, 1].min() - 1, stop=X_test[:, 1].max() + 1, step=0.01))
    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
                 alpha=0.75, cmap=ListedColormap(('red', 'green')))
    plt.xlim(X1.min(), X1.max())
    plt.ylim(X2.min(), X2.max())
    for i, j in enumerate(np.unique(y_test)):
        plt.scatter(X_test[y_test == j, 0], X_test[y_test == j, 1],
                    c=ListedColormap(('red', 'green'))(i), label=j)
    plt.title('Classifier (Test set)')
    plt.xlabel('Close')
    plt.ylabel('Signal')
    plt.legend()
    plt.show()